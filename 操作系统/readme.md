# 主要记录了操作系统相关知识

## 进程与线程
* 进程是资源分配的基本单位
* 线程是CPU调度的基本单位

## 进程、线程、协程的区别

### 进程
进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。进程是一种抽象的概念，从来没有统一的标准定义。

进程一般由程序、数据集合和进程控制块三部分组成：
- 程序：用于描述进程要完成的功能，是控制进程执行的指令集；
- 数据集合：是程序在执行时所需要的数据和工作区；
- 进程控制块（PCB）：包含进程的描述信息和控制信息，是进程存在的唯一标志；

进程具有的特征：
- 动态性：进程是程序的一次执行过程，是临时的，有生命周期的，是动态产生，动态消亡的；
- 并发性：任何进程都可以同其它进程一起并发执行；
- 独立性：进程是系统进行资源分配和调度的一个独立单位；
- 结构性：进程由程序、数据和进程控制块三部分组成；

### 线程
在早期的操作系统中没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。

后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程。

线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分配的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间。一个标准的线程由线程ID、当前指令指针（PC）、寄存器和堆栈组成。而进程由内存代码（代码、数据、进程空间、打开的文件）和一个或多个线程组成。

### 进程和线程的区别
- 进程是操作系统分配资源的基本单位，线程是程序执行的基本单位；
- 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；
- 进程之间互相独立，但同一进程下的各个线程之间共享程序的内存空间及一些进程级的资源（如打开文件和信号），某进程内的线程在其它进程不可见；
- 调度和切换：线程上下文切换比进程上下文切换要快得多；

![20220406194931](https://raw.githubusercontent.com/neicun1024/PicBed/main/images_for_markdown/20220406194931.png)

### 协程
协程（Coroutines）是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做**用户空间线程**，对内核来说不可见。

因为是自主开辟的异步任务，所以很多人也更喜欢叫它们纤程（Fiber），或者绿色线程（GreenThread）。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。

![20220406203215](https://raw.githubusercontent.com/neicun1024/PicBed/main/images_for_markdown/20220406203215.png)

当线程进行I/O操作时，一直处于阻塞状态，导致CPU处于空转状态，造成整个系统的吞吐量下降。另外，过多的线程会带来更多的ContextSwitch开销。

#### 协程的目的
当出现长时间的I/O操作时，通过让出目前的协程调度，执行下一个任务的方式，来消除ContextSwitch的开销。

#### 协程的特点
1. 线程的切换由操作系统负责调度，协程由用户自己进行调度，因此减少了上下文切换，提高了效率。
2. 线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程。
3. 由于在同一个线程上，因此可以避免竞争关系而使用锁。
4. 适用于被阻塞的，且需要大量并发的场景。但不适用于大量计算的多线程，遇到此种情况，更好是用协程去解决。

#### 协程的原理
当出现I/O阻塞的时候，由协程的调度器进行调度，通过将数据流理科yield掉（主动让出），并且记录当前栈上的数据，阻塞完后立刻再通知线程恢复栈，并把阻塞的结果放到这个线程上去跑，这样看上去好像跟写同步代码没有任何差别，这整个流程可以称为`coroutine`，而跑在由`coroutine`负责调度的线程称为`Fiber`。比如Golang里的go关键字其实就是负责开启一个`Fiber`，让`func`逻辑跑在上面。

由于协程的暂停完全由程序控制，发生在用户态上；而线程的阻塞状态是由操作系统内核来进行切换，发生在内核态上。因此，协程的开销远远小于线程的开销，也就没有了ContextSwitch上的开销。

### 线程和协程的区别

| 比较项 | 线程 | 协程 |
| ---- | ---- | ---- |
| 占用资源 | 初始单位为1MB，规定不可变 | 初始一般为2KB，可随需要而增大 |
| 调度所属  | 由OS的内核完成 | 由用户完成 |
| 切换开销 | 设计模式切换（由用户态切换到内核态）、16个寄存器、PC、SP等寄存器的刷新等 | 只有三个寄存器的值修改（PC、SP、DX） |
| 性能问题 | 资源占用太高，频繁创建销毁会带来严重的性能问题 | 资源占用小，不会带来严重的性能问题 |
| 数据同步 | 需要用锁等机制确保数据的一致性和可见性 | 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多 |


## 多线程、多核、内核线程
多核处理器是指在一个处理器上集成多个运算核心从而提高计算能力，也就是有多个真正并行计算的处理核心，每个处理核心对应一个内核线程。

内核线程（Kernel Thread，KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。一般一个处理核心对应一个内核线程，比如单核处理器对应一个内核线程，双核处理器对应两个内核线程，四核处理器对应四个内核线程。

程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口————轻量级进程（LWP），轻量级进程就是我们通常意义上所说的线程，也被叫做用户线程。由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。

用户线程与内核线程的对应关系由三种模型：
- 一对一模型：一个用户线程唯一地对应一个内核线程
  - 优点：
    1. 一个线程因某种原因阻塞时其他线程的执行不受影响
    2. 让多线程程序在多处理器的系统上有更好的表现
  - 缺点：
    1. 许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制
    2. 许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降
- 多对一模型：将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，系统内核感受不到线程的实现方式。用户线程的建立、同步、销毁等都在用户态中完成，不需要内核的介入。
  - 优点：
    1. 线程上下文切换速度要快许多
    2. 用户线程的数量几乎无限制
  - 缺点：
    1. 如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了
    2. 在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了
- 多对多模型：将多个用户线程映射到多个内核线程上。由线程库负责在可用的可调度实体上调度用户线程
  - 优点：
    1. 线程上下文切换非常快，因为它避免了系统调用
    2. 一个用户线程的阻塞不会导致所有线程的阻塞，因为此时还有别的内核线程被调度来执行
    3. 对用户线程的数量没有限制
    4. 在多处理器的操作系统中，多对多模型的线程也能得到一定的性能提升，但提升的幅度不如一对一模型的高
  - 缺点：
    1. 增加了复杂性和优先级倒置的可能性
    2. 在用户态调度程序和内核调度程序之间没有广泛（且高昂）协调的次优调度


## 进程之间的通信方式以及优缺点
* 管道(PIPE)：
    * 有名管道：一种半双工的通信方式，允许无亲缘关系进程间的通信
        * 优点：可以实现任意关系的进程间的通信
        * 缺点：
            1. 长期存在于系统中，使用不当容易出错
            2. 缓冲区有限
    * 匿名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
        * 优点：简单方便
        * 缺点：
            1. 局限于单向通信
            2. 只能创建在它的进程以及其有亲缘关系的进程之间
            3. 缓冲区有限
* 消息队列(Message Queue)：是消息的链表，存放在内核中并由消息队列标识符标识 
    * 和管道的对比：
        1. 匿名管道是跟随进程的，消息队列是跟随内核的，进程结束之后，匿名管道就死了，但是消息队列还会存在（除非显示调用函数销毁）
        2. 管道是文件，存放在磁盘上，访问速度慢，消息队列是数据结构，存放在内存，访问速度快
        3. 管道是数据流式存取，消息队列是数据块式存取
    * 优点：
        1.  对于交换少量数量的数据很有用，因为无需冲突避免
        2.  对于分布式系统，消息传递相比共享内存更易实现
    * 缺点：
        1. 消息传递的实现经常采用系统调用，需要消耗更多时间以便内核介入
* 信号(Signal)：一种比较复杂的通信方式，用于通知接受进程的某个事件已经发生，比如**CTRL+C**、**CTRL+Z**、**kill**等

* 共享内存(Shared Memory)：映射一段能被其它进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
    * 优点：
        1. 无需复制，快捷，信息量大
        2. 仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有访问都可作为常规内存访问，无需借助内核
    * 缺点：
        1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作存在同步问题
        2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
* 信号量(Semaphore)：一个计数器，可以用来控制多个进程对共享内存的访问
    * 优点：可以同步进程
    * 缺点：信号量有限
* 套接字(Socket)：可用于不同计算机间的进程通信
    * 优点：
        1. 传输数据为字节级，传输数据可自定义，数据量小效率高
        2. 传输数据时间短，性能高
        3. 适合于客户端和服务器端之间信息实时交互
        4. 可以加密，数据安全性强
    * 缺点：需要对传输的数据进行解析，转化成应用级的数据

## 线程同步的方式
* 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
    * 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法
    * 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的
    * 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁
    * 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用
* 信号量机制(Semaphore)
    * 无名线程信号量
    * 命名线程信号量
* 信号机制(Signal)：类似进程间的信号处理
* 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行

*线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制*


## 进程之间私有和共享的资源
* 私有：地址空间，包括代码段、堆、全局变量、栈等，寄存器
* 共享：公共数据，进程目录，进程 ID （这里是不是有问题？）

## 线程之间私有和共享的资源
* 私有：栈，寄存器，状态、程序计数器
* 共享：堆，地址空间，全局变量，静态变量

[线程间到底共享了哪些进程资源？](https://www.eet-china.com/mp/a35347.html)


## [进程描述符PCB的结构](https://labuladong.github.io/algo/5/35/)
```
struct task_struct {
	// 进程状态
	long			  state;
	// 虚拟内存结构体
	struct mm_struct  *mm;
	// 进程号
	pid_t			  pid;
	// 指向父进程的指针
	struct task_struct __rcu  *parent;
	// 子进程列表
	struct list_head		children;
	// 存放文件系统信息的指针
	struct fs_struct		*fs;
	// 一个数组，包含该进程打开的文件指针
	struct files_struct		*files;
};
```

## [进程上下文切换](https://cloud.tencent.com/developer/article/1710837)

### 进程上下文的概念

- 进程上下文是进程执行活动全过程的静态描述
- 我们把已执行过的进程指令和数据在相关寄存器与堆栈中的内容称为进程上文
- 把正在执行的指令和数据在寄存器与堆栈中的内容称为进程正文
- 把待执行的指令和数据在寄存器与堆栈中的内容称为进程下文

实际上linux内核中，进程上下文包括进程的虚拟地址空间和硬件上下文。

进程硬件上下文包含了当前cpu的一组寄存器的集合，arm64中使用task_struct结构的thread成员的cpu_context成员来描述，包括x19-x28, sp, pc等

![20220307203355](https://raw.githubusercontent.com/neicun1024/Interview/main/images_for_markdown/20220307203355.png)

### 上下文切换详细过程
进程上下文切换主要涉及到两部分主要过程：进程地址空间切换和处理器状态切换。

- 进程地址空间切换主要是针对用户进程而言，保证了进程访问指令数据时访问的是自己的地址空间，但是进程执行的内核栈还是前一个进程的，当前执行流也还是前一个进程的，需要做切换
- 处理器状态切换应对与所有的调度单位，将前一个进程的sp, pc等寄存器的值保存到一块内存上，然后将即将执行的进程的sp, pc等寄存器的值从另一块内存中恢复到相应寄存器中，恢复sp完成了进程内核栈的切换，恢复pc完成了指令执行流的切换


### 进程地址空间切换
![20220307204625](https://raw.githubusercontent.com/neicun1024/Interview/main/images_for_markdown/20220307204625.png)

- 进程地址空间指的是进程所拥有的虚拟地址空间，而这个地址空间是假的，是linux内核通过数据结构来描述出来的，从而使得每一个进程都感觉到自己拥有整个内存的假象，cpu访问的指令和数据最终会落实到实际的物理地址，对于进程而言通过缺页异常来分配和建立页表映射
- 进程地址空间内有进程运行的指令和数据，因此当调度器从其他进程重新切换到我的时候，为了保证当前进程访问的虚拟地址是自己的，必须切换地址空间
- 进程地址空间使用mm_struct结构体来描述，这个结构体被嵌入到进程描述符（我们通常所说的进程控制块PCB）task_struct中，mm_struct结构体将各个vma组织起来进行管理，其中有一个成员pgd至关重要，地址空间切换中最重要的是pgd的设置
- pgd（page global directory）中保存的是进程的页全局目录的虚拟地址，在fork（新建一个子进程）的时候，如果是创建进程，需要分配设置mm_struct，其中会分配进程页全局目录所在的页，然后将首地址赋值给pgd
- 如何实现地址空间切换？
  - 将进程的pgd虚拟地址转化为物理地址存放在ttbr0_el1（用户空间的页表基址寄存器）中，当访问用户空间地址的时候mmu会通过这个寄存器来做遍历页表获得物理地址；完成了这一步，也就完成了进程的地址空间切换，确切的说是进程的虚拟地址空间切换


### 处理器状态（硬件上下文）切换
![20220307210119](https://raw.githubusercontent.com/neicun1024/Interview/main/images_for_markdown/20220307210119.png)

- 由于用户空间通过异常/中断进入内核空间的时候都需要保存现场，也就是保存发生异常/中断时的所有通用寄存器的值，内核会把“现场”保存到每个进程特有的进程内核栈中，并用pt_regs结构来描述，当异常/中断处理完成之后会返回用户空间，返回之前会恢复之前保存的“现场”，用户程序继续执行
- 当进程切换的时候，当前进程被时钟中断打断，将发生中断时的现场保存到进程内核栈（如：sp, lr等），然后会切换到下一个进程，当再次切换回来的时候，返回用户空间的时候会恢复之前的现场，进程就可以继续执行（执行之前被中断打断的下一条指令，继续使用自己用户态sp），这对于用户进程来说是透明的


### 普通用户进程、普通用户线程、内核线程切换的差别
![20220307212446](https://raw.githubusercontent.com/neicun1024/Interview/main/images_for_markdown/20220307212446.png)
内核地址空间切换的时候有一下原则：看的是进程描述符的mm_struct结构，即是成员mm:
1. 如果mm为NULL，则表示即将切换的是内核线程，不需要切换地址空间（所有任务共享内核地址空间）
2. 内核线程会借用前一个用户进程的mm，赋值到自己的active_mm（本身的mm为空），进程切换的时候就会比较前一个进程的active_mm和当前进程的mm
3. 如果前一个任务和即将切换的任务具有相同的mm成员，就是共享地址空间的线程，不需要切换地址空间

- 所有的进程线程之间进行切换都需要切换处理器状态
- 对于普通的用户进程之间进行切换需要切换地址空间
- 同一个线程组中的线程之间切换不需要切换地址空间，因为他们共享相同的地址空间
- 内核线程在上下文切换的时候不需要切换地址空间，仅仅是借用上一个进程mm_struct结构


## 用户态和内核态：

[用户态线程和内核态线程有什么区别？](http://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%AE%8C/14%20%20%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%EF%BC%9A%E7%94%A8%E6%88%B7%E6%80%81%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%BA%BF%E7%A8%8B%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F.md)


## IO多路复用
[你管这破玩意叫 IO 多路复用？](https://mp.weixin.qq.com/s?__biz=Mzk0MjE3NDE0Ng==&mid=2247494866&idx=1&sn=0ebeb60dbc1fd7f9473943df7ce5fd95&chksm=c2c5967ff5b21f69030636334f6a5a7dc52c0f4de9b668f7bac15b2c1a2660ae533dd9878c7c&scene=21#wechat_redirect)


## [CTRL+C和kill的关系](http://blog.sina.com.cn/s/blog_716358dc0100lj6e.html)

CTRL+C向当前用户的进程组（process group，包括parent process，child process）中的child process的发送SIGINT signal，child process被终止后由系统再向parent process发送SIGINT signal，随之parent process被终止。所以单纯的使用kill -SIGINT是无法实现终止一个带有child process的parent process，使用kill -SIGKILL终止parent process，只会导致child process成为孤儿进程。所以如果向使用代码的方式终止带有child process的parent process，必须先将所有child process终止掉，才能让parent process终止。


## [协程](https://www.cnblogs.com/Survivalist/p/11527949.html)


## [悲观锁和乐观锁](https://zhuanlan.zhihu.com/p/40211594)

### 悲观锁
总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

### 乐观锁
总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

### 乐观锁常见的两种实现方式：

#### 1. 版本号

一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功
![20220403104945](https://raw.githubusercontent.com/neicun1024/PicBed/main/images_for_markdown/20220403104945.png)

#### 2. CAS

compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数
- 需要读写的内存值 V
- 进行比较的值 A
- 拟写入的新值 B
当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

### 乐观锁的缺点

#### 1. ABA问题

如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。

#### 2. 循环时间长开销大

自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

#### 3. 只能保证一个共享变量的原子操作

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。


## 公平锁和非公平锁
- 公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。
    - 优点：所有的线程都能得到资源，不会饿死在队列中
    - 缺点：吞吐量会小，队列里除了第一个线程，其它的线程都会阻塞，CPU唤醒阻塞线程的开销会很大
- 非公平锁：多个线程去获取锁的时候，会直接去尝试获取，如果获取不到再进入等待队列，如果能获取到，就直接获取到锁
    - 优点：可以减少CPU需要唤醒的线程的数量，从而减少唤醒线程的开销，吞吐量大
    - 缺点：可能导致某些线程饿死，长时间获取不到锁


## 原子操作

### 原子操作的概念
原子操作就是一个独立而不可分割的操作。

- 在单核环境中
  - 一般意义下，原子操作中线程不会被切换，线程切换要么在原子操作之前，要么在原子操作完成之后。
  - 更广泛的意义下，原子操作是指一系列必须整体完成的操作步骤，如果任何一步操作没有完成，那么所有完成的步骤都必须回滚。
  - 例如在单核系统里，单个的机器指令可以看成是原子操作（如果有编译器优化、乱序执行等情况除外）；
- 在多核系统中
  - 单个的机器指令不是原子操作，因为多核系统里是多指令流并行运行的，一个核在执行一个指令时，其它核同时执行的指令有可能操作同一块内存区域，从而出现数据竞争现象。
  - 原子操作通常使用内存栅障（memory barrier）来实现，即一个CPU核在执行原子操作时，其它CPU核必须停止对内存或者不对指定的内存进行操作，这样才能避免数据竞争问题

在C++11之前，C++标准并没有对原子操作进行规定。VS和GCC编译器提供的原子操作的API。
- Windows原子操作API

    Win32 API中常见的原子操作主要有三类
    - 原子加1减1操作
      
      `LONG InterlockedIncrement( LONG volatile* Addend);`
      `LONG InterlockedDecrement( LONG volatile* Addend);`
    - 比较并交换操作
      
      `LONG InterlockedCompareExchange( LONG volatile*Destination, LONG Exchange, LONG Comperand );`
      
      这个操作是先将Comperand的值和Destination指向变量的值进行比较，如果相等就将Exchange变量的值赋给Destination指向的变量。返回值为未修改前的Destination位置的初始值。
    - 原子写操作
      
      `LONG InterlockedExchange( LONG volatile* Target, LONG Value);`
      
      InterlockedExchange的作用为将Value的值赋给Target指向的变量，返回Target指向变量未被赋值前的值。

- GCC编译器提供的原子操作API
    ```
    type __sync_fetch_and_add (type *ptr, type value);
    type __sync_fetch_and_sub (type *ptr, type value);
    type __sync_fetch_and_or (type *ptr, type value);
    type __sync_fetch_and_and (type *ptr, type value);
    type __sync_fetch_and_xor (type *ptr, type value);
    type __sync_fetch_and_nand (type *ptr, type value);
    type __sync_add_and_fetch (type *ptr, type value);
    type __sync_sub_and_fetch (type *ptr, type value);
    type __sync_or_and_fetch (type *ptr, type value);
    type __sync_and_and_fetch (type *ptr, type value);
    type __sync_xor_and_fetch (type *ptr, type value);
    type __sync_nand_and_fetch (type *ptr, type value);
    ```

- C++11提供的原子操作
  
  C++11中在<atomic>中定义了atomic模板类，atomic的模板参数类型可以为int、long、bool等等，C++中称为trivially copyable type。atomic_int、atomic_long为atomic模板实例化后的宏定义。atomic具体的原子操作函数可以参考[这里](http://www.cplusplus.com/reference/atomic/atomic/?kw=atomic)。


### 原子操作的底层实现

基于总线加锁和缓存加锁。

#### 总线加锁

早期的时候，当cpu执行lock指令的时候，会直接进行总线锁，就是把总线锁住，这样cpu和内存之间就不能进行通信，如果多核cpu，就出现了一核工作，多核围观的尴尬局面，此时就会出现严重的资源浪费问题，开销比较大。

#### 缓存加锁

后面有了缓存锁，缓存锁不再锁总线，而是在写回内存时，通过一致性机制来保证一个时刻只有一个核心能修改指定的内存区域。

#### 何时使用

有些场景是不能使用的缓存锁的，只能进行总线锁

    - 当操作的数据不能被缓存在处理器内部
    - 跨多个缓存行操作
    - 处理器不支持

这篇[博客](https://codelover.me/atomic/)看起来挺硬核的，目前我还不太理解。


## Python的GIL（全局解释锁）

GIL是计算机程序设计语言解释器用于同步线程的一种机制，它使得任何时刻仅有一个线程在执行。即便在多核心处理器上，使用GIL的解释器也只允许同一时间执行一个线程。常见的使用GIL的解释器有CPython和Ruby MRI。

## Python的线程池

系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。在这种情形下，使用线程池可以很好地提升性能，尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。

线程池在系统启动时即创建大量空闲的线程，程序只要将一个函数提交给线程池，线程池就会启动一个空闲的线程来执行它。当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。

此外，使用线程池可以有效地控制系统中并发线程的数量。当系统中包含有大量的并发线程时，会导致系统性能急剧下降，甚至导致 Python 解释器崩溃，而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。